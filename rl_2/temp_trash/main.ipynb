{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad163cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8408c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-15 14:25:39,144] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x86_64-conda-linux-gnu-cc: fatal error: cannot execute 'cc1': execvp: No such file or directory\n",
      "compilation terminated.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/home1/vaithina/.conda/envs/rl_chess/bin/x86_64-conda-linux-gnu-cc', '/tmp/SLURM_2338054/tmpycaabnjd/main.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/SLURM_2338054/tmpycaabnjd/cuda_utils.cpython-311-x86_64-linux-gnu.so', '-lcuda', '-L/home1/vaithina/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/lib', '-L/lib64', '-L/lib', '-I/home1/vaithina/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/include', '-I/tmp/SLURM_2338054/tmpycaabnjd', '-I/home1/vaithina/.conda/envs/rl_chess/include/python3.11']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Tuple, Union\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/__init__.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     23\u001b[39m     HAS_TRITON = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_inject\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_accelerator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lion\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse_attention\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transformer\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fp_quantizer\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerLayer, DeepSpeedTransformerConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# DeepSpeed Team\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerLayer, DeepSpeedTransformerConfig\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedInferenceConfig\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_implementations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mds_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerInference\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmoe_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedMoEInferenceConfig, DeepSpeedMoEInference\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/inference/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# DeepSpeed Team\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedInferenceConfig\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_implementations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mds_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerInference\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmoe_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedMoEInferenceConfig, DeepSpeedMoEInference\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/model_implementations/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# DeepSpeed Team\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mds_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerInference\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclip_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DSClipEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/model_implementations/transformers/ds_transformer.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deepspeed.HAS_TRITON \u001b[38;5;129;01mand\u001b[39;00m get_accelerator().is_triton_supported():\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TritonMLP\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TritonSelfAttention\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDeepSpeedTransformerInference\u001b[39;00m(nn.Module):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/inference/triton/__init__.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgelu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msoftmax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m softmax\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatmul_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fp16_matmul, matmul_4d, score_4d_matmul, context_4d_matmul\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/inference/triton/ops.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# DeepSpeed Team\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatmul_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatmul_ext\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mop_binding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer_norm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerNormOp\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer_norm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layer_norm, layer_norm_residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfilelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriton_matmul_kernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton_matmul_kernel\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mopen\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/deepspeed/ops/transformer/inference/triton/triton_matmul_kernel.py:51\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m configs\n\u001b[32m     45\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03mfp16 matmul implementation is adapted from triton matmul:\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03mhttps://github.com/openai/triton/blob/34817ecc954a6f4ca7b4dfb352fdde1f8bd49ca5/python/triton/ops/matmul.py\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautotune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# basic configs for compute-bound matmuls\u001b[39;49;00m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCACHE_M\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCACHE_N\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCACHE_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprune_configs_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mearly_config_prune\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fp16_matmul_prune_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mperf_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAUTOTUNE_TOP_K\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheuristics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEVEN_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mK\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBLOCK_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPLIT_K\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m_fp_matmul\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_am\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_ak\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_bk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_bn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_cm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride_cn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCACHE_M\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCACHE_N\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCACHE_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBLOCK_M\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBLOCK_N\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBLOCK_K\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mGROUP_M\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSPLIT_K\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEVEN_K\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mACC_TYPE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBIAS_ADD\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mACTIVATION\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# matrix multiplication\u001b[39;49;00m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogram_id\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpid_z\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogram_id\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/autotuner.py:368\u001b[39m, in \u001b[36mautotune.<locals>.decorator\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorator\u001b[39m(fn):\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAutotuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_to_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mpost_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprune_configs_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprune_configs_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                     \u001b[49m\u001b[43muse_cuda_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cuda_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/autotuner.py:130\u001b[39m, in \u001b[36mAutotuner.__init__\u001b[39m\u001b[34m(self, fn, arg_names, configs, key, reset_to_zero, restore_value, pre_hook, post_hook, prune_configs_by, warmup, rep, use_cuda_graph, do_bench)\u001b[39m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_bench \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28mself\u001b[39m.do_bench = \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_benchmarker\u001b[49m()\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m.do_bench = do_bench\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/driver.py:23\u001b[39m, in \u001b[36mLazyProxy.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._obj, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/driver.py:20\u001b[39m, in \u001b[36mLazyProxy._initialize_obj\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         \u001b[38;5;28mself\u001b[39m._obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/driver.py:9\u001b[39m, in \u001b[36m_create_driver\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actives) != \u001b[32m1\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(actives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactives\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). There should only be one.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactives\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/driver.py:450\u001b[39m, in \u001b[36mCudaDriver.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28mself\u001b[39m.utils = \u001b[43mCudaUtils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: make static\u001b[39;00m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.launcher_cls = CudaLauncher\n\u001b[32m    452\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/driver.py:80\u001b[39m, in \u001b[36mCudaUtils.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     mod = \u001b[43mcompile_module_from_src\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdriver.c\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda_utils\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.load_binary = mod.load_binary\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_device_properties = mod.get_device_properties\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/driver.py:57\u001b[39m, in \u001b[36mcompile_module_from_src\u001b[39m\u001b[34m(src, name)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     56\u001b[39m     f.write(src)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m so = \u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary_dirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibraries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(so, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     59\u001b[39m     cache_path = cache.put(f.read(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.so\u001b[39m\u001b[33m\"\u001b[39m, binary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/runtime/build.py:50\u001b[39m, in \u001b[36m_build\u001b[39m\u001b[34m(name, src, srcdir, library_dirs, include_dirs, libraries)\u001b[39m\n\u001b[32m     48\u001b[39m cc_cmd += [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-L\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m library_dirs]\n\u001b[32m     49\u001b[39m cc_cmd += [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-I\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include_dirs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m ret = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret == \u001b[32m0\u001b[39m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m so\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rl_chess/lib/python3.11/subprocess.py:413\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    412\u001b[39m         cmd = popenargs[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['/home1/vaithina/.conda/envs/rl_chess/bin/x86_64-conda-linux-gnu-cc', '/tmp/SLURM_2338054/tmpycaabnjd/main.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/SLURM_2338054/tmpycaabnjd/cuda_utils.cpython-311-x86_64-linux-gnu.so', '-lcuda', '-L/home1/vaithina/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/lib', '-L/lib64', '-L/lib', '-I/home1/vaithina/.conda/envs/rl_chess/lib/python3.11/site-packages/triton/backends/nvidia/include', '-I/tmp/SLURM_2338054/tmpycaabnjd', '-I/home1/vaithina/.conda/envs/rl_chess/include/python3.11']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import time\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import deepspeed\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from deepspeed import DeepSpeedEngine\n",
    "from tqdm import trange\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "from rewards import format_reward_sample, accuracy_reward_sample, compute_reward\n",
    "from data import get_data\n",
    "from model import get_model\n",
    "\n",
    "import wandb\n",
    "from utils import (\n",
    "    compute_token_log_probs,\n",
    "    dump_episodes,\n",
    "    evaluate_on_test_set,\n",
    "    find_free_port,\n",
    "    find_last_checkpoint,\n",
    "    prepare_model_inputs,\n",
    "    load_model_into_vllm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to stop DeepSpeed from complaining\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = str(find_free_port())\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "os.environ['VLLM_USE_V1']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# Total number of training iterations\n",
    "NUM_ITERATIONS = 1000\n",
    "NUM_SAMPLES = 1\n",
    "# Number of responses to generate for each input prompt (i.e. group size in GRPO)\n",
    "GENERATIONS_PER_SAMPLE = 16\n",
    "# Number of episodes to collect per iteration for training\n",
    "EPISODES_PER_ITERATION = NUM_SAMPLES * GENERATIONS_PER_SAMPLE\n",
    "# Controls how much the policy can deviate from the reference model\n",
    "KL_COEFFICIENT = 0.001\n",
    "\n",
    "SAVE_STEPS = 20\n",
    "EVAL_STEPS = 50\n",
    "\n",
    "# Training hyperparameters\n",
    "# Batch size for each GPU device during training\n",
    "PER_DEVICE_BATCH_SIZE = 8\n",
    "# Learning rate for model updates\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# Sampling parameters\n",
    "# Maximum number of tokens to generate in each response\n",
    "MAX_RESPONSE_TOKENS = 512\n",
    "# Controls randomness in generation (higher = more random)\n",
    "TEMPERATURE = 1.0\n",
    "# Nucleus sampling parameter (1.0 = disabled)\n",
    "TOP_P = 1.0\n",
    "# Top-k sampling parameter (-1 = disabled)\n",
    "TOP_K = -1  # no top k\n",
    "\n",
    "# DeepSpeed configuration\n",
    "# DeepSpeed config for the policy model\n",
    "deepspeed_config = {\n",
    "    \"bf16\": {\"enabled\": True},\n",
    "    \"zero_optimization\": {\"stage\": 2, \"overlap_comm\": False},\n",
    "    \"train_batch_size\": EPISODES_PER_ITERATION,\n",
    "    \"train_micro_batch_size_per_gpu\": PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_accumulation_steps\": EPISODES_PER_ITERATION // PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": LEARNING_RATE,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"torch_adam\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "# DeepSpeed config for the reference model\n",
    "ref_deepspeed_config = {\n",
    "    \"bf16\": {\"enabled\": True},\n",
    "    # Note that we don't train the reference model\n",
    "    # These are just for compatibility with DeepSpeed.\n",
    "    \"train_batch_size\": EPISODES_PER_ITERATION,\n",
    "    \"train_micro_batch_size_per_gpu\": PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_accumulation_steps\": EPISODES_PER_ITERATION // PER_DEVICE_BATCH_SIZE,\n",
    "}\n",
    "\n",
    "RUN_NAME = \"qwen_rl_chess_test\"\n",
    "EXP_DIR = Path(\"outputs\") / RUN_NAME\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Logs and Checkpoints will be saved to: {EXP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "EOS_TOKEN_ID = AutoTokenizer.from_pretrained(MODEL_NAME).eos_token_id\n",
    "EOS_TOKEN = tokenizer.convert_ids_to_tokens(EOS_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_data(tokenizer)\n",
    "train_dataset = ds['train']\n",
    "test_dataset = ds['test']\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0864f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target: \", train_dataset[0][\"fen\"])\n",
    "print(\"Available Numbers: \", train_dataset[0][\"best_move\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f45e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_reward_sample(\"<think>I think the answer is </think>\\n<answer>1+2</answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_reward_sample(\"I think the answer is </think>\\n<answer>1+2</answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_reward_sample(\"I think the answer is </think>\\n<answer>1+2</answer>\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a201f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_reward_sample(\"<reasoning>asdffsd</reasoning><best_move>Nxa3</best_move>\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba381ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_episodes(samples, all_generations, all_finish_reasons):\n",
    "    assert len(all_generations) == len(all_finish_reasons)\n",
    "    assert len(all_generations) == len(samples) * GENERATIONS_PER_SAMPLE\n",
    "\n",
    "    groups = [\n",
    "        list(range(i, i + GENERATIONS_PER_SAMPLE))\n",
    "        for i in range(0, len(all_generations), GENERATIONS_PER_SAMPLE)\n",
    "    ]\n",
    "\n",
    "    all_query_token_ids, all_responses_token_ids, all_advantages = [], [], []\n",
    "\n",
    "    stats = {\n",
    "        'response_lengths': [],\n",
    "        'rewards': [],\n",
    "        'non_stop_rate': [],\n",
    "    }\n",
    "\n",
    "    for sample, group_indices in zip(samples, groups):\n",
    "        finish_reasons = [all_finish_reasons[i] for i in group_indices]\n",
    "        response_token_ids = [all_generations[i] for i in group_indices]\n",
    "        responses = tokenizer.batch_decode(response_token_ids, skip_special_tokens=False)\n",
    "\n",
    "        rewards_and_metrics = [compute_reward(resp, sample) for resp in responses]\n",
    "        rewards, reward_metrics = zip(*rewards_and_metrics)\n",
    "        rewards = np.array(rewards)\n",
    "        response_advantages = (rewards - rewards.mean()) / (rewards.std() + 1e-4)\n",
    "\n",
    "        advantages = [\n",
    "            [resp_adv] * len(resp)\n",
    "            for resp_adv, resp in zip(response_advantages, response_token_ids)\n",
    "        ]\n",
    "\n",
    "        all_query_token_ids.extend([sample['input_ids']] * GENERATIONS_PER_SAMPLE)\n",
    "        all_responses_token_ids.extend(response_token_ids)\n",
    "        all_advantages.extend(advantages)\n",
    "\n",
    "        stats['rewards'].extend(rewards)\n",
    "        stats['non_stop_rate'].extend([fr != 'stop' for fr in finish_reasons])\n",
    "        stats['response_lengths'].extend([len(ids) for ids in response_token_ids])\n",
    "\n",
    "        for rm in reward_metrics:\n",
    "            for k, v in rm.items():\n",
    "                stats.setdefault(f\"reward_metrics/{k}\", []).append(v)\n",
    "\n",
    "    episodes = {\n",
    "        'all_query_token_ids': all_query_token_ids,\n",
    "        'all_response_token_ids': all_responses_token_ids,\n",
    "        'all_advantages': all_advantages,\n",
    "    }\n",
    "    return episodes, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_0 = {\n",
    "#     \"sample\": {\"input_ids\": [1,2,3], \"nums\": [1,2,3], \"target\": 6},\n",
    "#     \"generations\": [[4,5, 22, 33], [6,7], [8,9, 11], [10,11]],\n",
    "#     \"finish_reasons\": [\"stop\", \"length\", \"stop\", \"stop\"]\n",
    "# }\n",
    "\n",
    "# case = case_0\n",
    "# episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "# episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_1 = {\n",
    "#     \"sample\": {\"input_ids\": [33, 44], \"nums\": [11, 7, 8], \"target\": 26},\n",
    "#     \"generations\": [[1,2], [3,4], [5,6], [7,8]],\n",
    "#     \"finish_reasons\": [\"stop\", \"stop\", \"length\", \"stop\"]\n",
    "# }\n",
    "# case = case_1\n",
    "# episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "# episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0704fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_2 = {\n",
    "#     \"sample\": {\"input_ids\": [9, 8, 7, 6, 5, 4], \"nums\": [1,2,3,4], \"target\": 10},\n",
    "#     \"generations\": [[9,10], [11,12], [13,14], [15,16]],\n",
    "#     \"finish_reasons\": [\"length\", \"length\", \"stop\", \"stop\"]\n",
    "# }\n",
    "# case = case_2\n",
    "# episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "# episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pg_loss(policy_model, reference_model, batch, total_response_len):\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "    advantages = batch['advantages']\n",
    "\n",
    "    labels_mask = (labels[..., 1:] != -100).float()\n",
    "\n",
    "    model_inputs = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels,\n",
    "        # 'labels_mask': labels_mask,\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_logps = compute_token_log_probs(\n",
    "            reference_model, model_inputs, TEMPERATURE\n",
    "        )\n",
    "\n",
    "    logps = compute_token_log_probs(policy_model, model_inputs, TEMPERATURE)\n",
    "\n",
    "    kl_penalty = torch.exp(ref_logps - logps) - (ref_logps - logps) - 1\n",
    "    kl_penalty = kl_penalty * labels_mask\n",
    "\n",
    "    entropy = -logps.sum() / labels_mask.sum()\n",
    "\n",
    "    policy_loss = -logps * advantages[..., 1:]\n",
    "    policy_loss = policy_loss * labels_mask\n",
    "\n",
    "    loss = (policy_loss + KL_COEFFICIENT * kl_penalty).sum() / total_response_len\n",
    "\n",
    "    metrics = {\n",
    "        'policy_loss': policy_loss.sum().item() / total_response_len,\n",
    "        'kl_penalty': kl_penalty.sum().item() / total_response_len,\n",
    "        'entropy': entropy.item() / total_response_len\n",
    "    }\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize main and reference models\n",
    "policy_model, _ = get_model(MODEL_NAME)\n",
    "reference_model, _ = get_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f001d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={'use_reentrant': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model, *_ = deepspeed.initialize(\n",
    "    model=policy_model,\n",
    "    config=deepspeed_config,\n",
    "    model_parameters=policy_model.parameters(),\n",
    ")\n",
    "reference_model, *_ = deepspeed.initialize(\n",
    "    model=reference_model,\n",
    "    config=deepspeed_config,\n",
    ")\n",
    "reference_model.module.cpu()\n",
    "\n",
    "# print(reference_model.device)\n",
    "# reference_model.cpu()\n",
    "# print(reference_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_engine = LLM(\n",
    "    model=MODEL_NAME,\n",
    "    skip_tokenizer_init=False,\n",
    "    gpu_memory_utilization=0.5,\n",
    "    enable_prefix_caching=True,\n",
    "    swap_space=1,\n",
    "    scheduling_policy=\"fcfs\",\n",
    "    dtype=torch.bfloat16,\n",
    "    max_model_len=768,\n",
    "    enable_sleep_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint if it exists\n",
    "begin_iter = 0\n",
    "ckpt_path, ckpt_iter = find_last_checkpoint(EXP_DIR)\n",
    "if ckpt_path is not None:\n",
    "    print(f\"Resuming from checkpoint {ckpt_path} at iteration {ckpt_iter}\")\n",
    "    out = policy_model.load_checkpoint(ckpt_path / \"deepspeed\")\n",
    "    if out is None:\n",
    "        raise RuntimeError(f\"Failed to load checkpoint {ckpt_path}\")\n",
    "    begin_iter = ckpt_iter + 1\n",
    "    load_model_into_vllm(policy_model, inference_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in trange(NUM_ITERATIONS):\n",
    "    print(f\"Iteration {iteration}/{NUM_ITERATIONS}\")\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    eval_stats = None\n",
    "    if iteration % EVAL_STEPS == 0:\n",
    "        print(\"Evaluating on eval set...\")\n",
    "        eval_episodes, eval_stats = evaluate_on_test_set(\n",
    "            inference_engine=inference_engine,\n",
    "            test_dataset=test_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            eos_token=EOS_TOKEN,\n",
    "            eval_sampling_params=SamplingParams(\n",
    "                temperature=0.3,\n",
    "                max_tokens=1024,\n",
    "                n=1,\n",
    "                detokenize=False,\n",
    "                stop_token_ids=[EOS_TOKEN_ID],\n",
    "            ),\n",
    "            reward_func=lambda completion, sample: compute_reward(\n",
    "                completion, sample\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    num_samples = EPISODES_PER_ITERATION // GENERATIONS_PER_SAMPLE\n",
    "    indices = np.random.choice(\n",
    "        len(train_dataset), size=num_samples, replace=False\n",
    "    )\n",
    "    samples = train_dataset.select(indices)\n",
    "\n",
    "    # Sample responses\n",
    "    outputs = inference_engine.generate(\n",
    "        prompt_token_ids=list(samples[\"input_ids\"]),\n",
    "        sampling_params=SamplingParams(\n",
    "            n=GENERATIONS_PER_SAMPLE,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P,\n",
    "            top_k=TOP_K,\n",
    "            max_tokens=MAX_RESPONSE_TOKENS,\n",
    "            detokenize=False,\n",
    "            stop_token_ids=[EOS_TOKEN_ID],\n",
    "        )\n",
    "    )\n",
    "    all_generations = [list(g.token_ids) for out in outputs for g in out.outputs]\n",
    "    all_finish_reasons = [g.finish_reason for out in outputs for g in out.outputs]\n",
    "    inference_engine.sleep(1)\n",
    "\n",
    "    print(f\"Generated {len(all_generations)} responses\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Process responses and calculate rewards\n",
    "    episodes, episodes_stats = create_training_episodes(\n",
    "        samples,\n",
    "        all_generations,\n",
    "        all_finish_reasons,\n",
    "    )\n",
    "    for k, v in episodes_stats.items():\n",
    "        metrics.setdefault(k, []).extend(v)\n",
    "\n",
    "    episode_table = dump_episodes(\n",
    "        episodes=episodes,\n",
    "        episodes_stats=episodes_stats,\n",
    "        exp_dir=EXP_DIR,\n",
    "        tokenizer=tokenizer,\n",
    "        iteration=iteration,\n",
    "    )\n",
    "\n",
    "    #########################################################\n",
    "    # Training\n",
    "    #########################################################\n",
    "\n",
    "    # Prepare training batch\n",
    "    model_inputs = prepare_model_inputs(\n",
    "        query_token_ids=episodes[\"all_query_token_ids\"],\n",
    "        response_token_ids=episodes[\"all_response_token_ids\"],\n",
    "        advantages=episodes[\"all_advantages\"],\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    # Calculate losses and update model\n",
    "    policy_model.train()\n",
    "    # reference_model.cuda()\n",
    "    # deepspeed\n",
    "    reference_model.module.cuda()\n",
    "    reference_model.eval()\n",
    "\n",
    "    total_response_len = (model_inputs[\"labels\"] != -100).sum().item()\n",
    "\n",
    "    for i in trange(0, EPISODES_PER_ITERATION, PER_DEVICE_BATCH_SIZE, desc=\"Gradient Accumulation\"):\n",
    "        batch = {\n",
    "            k: v[i : i + PER_DEVICE_BATCH_SIZE]\n",
    "            for k, v in model_inputs.items()\n",
    "        }\n",
    "\n",
    "        # Compute policy gradient loss\n",
    "        loss, loss_metrics = compute_pg_loss(\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            batch=batch,\n",
    "            total_response_len=total_response_len,\n",
    "        )\n",
    "\n",
    "        # Track metrics\n",
    "        metrics.setdefault(\"loss\", []).append(loss.item())\n",
    "        # grad_norm = policy_model.get_global_grad_norm()\n",
    "        # if grad_norm is not None:\n",
    "        #     grad_norm = grad_norm.item()\n",
    "        # metrics.setdefault(\"grad_norm\", []).append(grad_norm)\n",
    "        for k, v in loss_metrics.items():\n",
    "            metrics.setdefault(k, []).append(v.item() if isinstance(v, torch.Tensor) else v)\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        policy_model.backward(loss, scale_wrt_gas=False)\n",
    "        \n",
    "        # Free memory\n",
    "        del loss, loss_metrics\n",
    "        if policy_model.is_gradient_accumulation_boundary():\n",
    "            # reference_model.cpu()\n",
    "            # deepspeed\n",
    "            reference_model.module.cpu()\n",
    "\n",
    "        policy_model.step()\n",
    "\n",
    "    #########################################################\n",
    "    # Update inference engine weights\n",
    "    #########################################################\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "    inference_engine.wake_up()\n",
    "    load_model_into_vllm(policy_model, inference_engine)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    #########################################################\n",
    "    # Log metrics\n",
    "    #########################################################\n",
    "\n",
    "    train_metrics = {\n",
    "        k: np.mean(v) for k, v in metrics.items() if None not in v\n",
    "    }\n",
    "    train_metrics[\"learning_rate\"] = policy_model.get_lr()[0]\n",
    "    logs = {\n",
    "        \"iteration\": iteration,\n",
    "        f\"episodes/iter_{iteration:06d}\": episode_table,\n",
    "        **{f\"train/{k}\": v for k, v in train_metrics.items()},\n",
    "    }\n",
    "    if eval_stats is not None:\n",
    "        eval_metrics = {k: np.mean(v) for k, v in eval_stats.items() if None not in v}\n",
    "        logs.update({f\"eval/{k}\": v for k, v in eval_metrics.items()})\n",
    "    # wandb.log(logs)\n",
    "\n",
    "    selected_keys = [\n",
    "        \"train/kl_penalty\",\n",
    "        \"train/rewards\",\n",
    "        \"train/reward_metrics/format_reward\",\n",
    "        \"train/reward_metrics/equation_reward\",\n",
    "        \"eval/rewards\",\n",
    "        \"eval/reward_metrics/format_reward\",\n",
    "        \"eval/reward_metrics/equation_reward\",\n",
    "    ]\n",
    "    selected_metrics = {k: logs[k] for k in selected_keys if k in logs}\n",
    "    print(f\"KEY METRICS: {selected_metrics}\")\n",
    "\n",
    "    if iteration % SAVE_STEPS == 0 and iteration != 0:\n",
    "        # policy_model.save_pretrained(\n",
    "        #     str(EXP_DIR / \"checkpoints\" / f\"ckpt_{iteration:06d}\" / \"hf_model\")\n",
    "        # )\n",
    "        # deepspeed\n",
    "        policy_model.module.save_pretrained(\n",
    "            str(EXP_DIR / \"checkpoints\" / f\"ckpt_{iteration:06d}\" / \"hf_model\")\n",
    "        )\n",
    "        policy_model.save_checkpoint(\n",
    "            str(EXP_DIR / \"checkpoints\" / f\"ckpt_{iteration:06d}\" / \"deepspeed\")\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
